{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxajee203XYmT1rwGzJk1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomGermeau/BlancPain/blob/main/code/Update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E79xKY1qZe1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cd40b6-a54e-4ef6-ef24-4734837d41e2"
      },
      "source": [
        "# Install and update spaCy\n",
        "!pip install -U spacy\n",
        "\n",
        "# Download the english language model\n",
        "!python -m spacy download fr_core_news_sm\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 22.8 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n",
            "Collecting fr-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.2.0/fr_core_news_sm-3.2.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 23.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-__VmJCRWLSS"
      },
      "source": [
        "# Import required packages\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9tFeOkWNk5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "991cf4b2-84f5-428d-a21f-8a72eb6100e3"
      },
      "source": [
        "# read in training data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/TomGermeau/BlancPain/main/data/training_data.csv\")\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                           sentence difficulty\n",
              "0   0  Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2   2  Le test de niveau en français est sur le site ...         A1\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   4  Dans les écoles de commerce, dans les couloirs...         B1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wG5NSuiYJn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4881f2cb-a622-43f6-e411-d441c7703f5f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4800 entries, 0 to 4799\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          4800 non-null   int64 \n",
            " 1   sentence    4800 non-null   object\n",
            " 2   difficulty  4800 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 112.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.read_csv(\"https://raw.githubusercontent.com/TomGermeau/BlancPain/main/data/unlabelled_test_data.csv\")\n",
        "df_pred.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vqUXvWtTLE9y",
        "outputId": "6bf03e2b-b9d3-4f68-f19e-f3ff2d840f70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                           sentence\n",
              "0   0  Nous dûmes nous excuser des propos que nous eû...\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2   2  Et, paradoxalement, boire froid n'est pas la b...\n",
              "3   3  Ce n'est pas étonnant, car c'est une saison my...\n",
              "4   4  Le corps de Golo lui-même, d'une essence aussi..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline"
      ],
      "metadata": {
        "id": "qAGFBL1U9m-e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45HqWbeAYMTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65195a0e-053b-435c-e46c-87b583c49b29"
      },
      "source": [
        "percenteges= df.difficulty.value_counts(normalize=True)\n",
        "percenteges"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1    0.169375\n",
              "C2    0.168125\n",
              "C1    0.166250\n",
              "B1    0.165625\n",
              "A2    0.165625\n",
              "B2    0.165000\n",
              "Name: difficulty, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = max(percenteges)\n",
        "baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6k7wyr8wes0",
        "outputId": "36cd619f-85b7-4198-d23b-0afc1361a432"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.169375"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Split"
      ],
      "metadata": {
        "id": "k9ocLMc_9rLX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87dc135a-2bc2-4cc2-bf48-aa5531ade12a",
        "id": "0kGeUuwz4-2h"
      },
      "source": [
        "X = df['sentence'] # the features we want to analyze\n",
        "ylabels = df['difficulty'] # the labels, or answers, we want to test against\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "#X_vectorized = vectorizer.fit_transform(X).todense()\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70                                Comment t'appelles-tu ?\n",
              "4347    Voilà qui serait en effet de nature à simplifi...\n",
              "1122    Les pèlerins partagèrent alors cette célébrati...\n",
              "4570                          Qu'est-ce que vous faites ?\n",
              "34      En voici un des moins obscurs : \"Plus nous dev...\n",
              "                              ...                        \n",
              "1033    Les micro-changements apportés par ce type d'u...\n",
              "3264    J'allais à la poste quand j'ai croisé ma cousi...\n",
              "1653    Au cours des années 1970 et 1980, plusieurs gr...\n",
              "2607    Stop : tout d'abord, figurez-vous que les vrai...\n",
              "2732    \"On s'est alors dit que le terrain commençait ...\n",
              "Name: sentence, Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for evaluation"
      ],
      "metadata": {
        "id": "OS1K4L6J-R3P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692K-omi9hFo"
      },
      "source": [
        "def evaluate(test, pred):\n",
        "    precision = precision_score(test, pred, \n",
        "                                           pos_label='positive',\n",
        "                                           average='micro')\n",
        "    recall = recall_score(test, pred, \n",
        "                                           pos_label='positive',\n",
        "                                           average='micro')\n",
        "    f1 = f1_score(test, pred, average='micro')\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(test, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(test, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression (without data cleaning)"
      ],
      "metadata": {
        "id": "5FqIba0y92z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', vectorizer),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "#instantiate the estimator\n",
        "#LR = LogisticRegression()\n",
        "\n",
        "# fit the estimator to our labelled data (input matrix and target vector)\n",
        "#LR.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I5UOVed65hP",
        "outputId": "80af366e-2164-4284-9b48-58426b9019be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifier', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict y_test\n",
        "pred_LR = pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "n9ybeaJ075rX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print confusion matrix, accurancy score, precision, recore and F1_score\n",
        "evaluate(y_test, pred_LR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_u4ybBRAM6j",
        "outputId": "c66d6246-0a9a-4293-8d14-d1ce6db5e222"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[93 31 21 10  4  2]\n",
            " [54 60 30  6  6  8]\n",
            " [12 38 64 17  9 20]\n",
            " [ 6  6 15 66 27 24]\n",
            " [ 4  4 10 37 73 45]\n",
            " [ 7  8  8 19 24 92]]\n",
            "ACCURACY SCORE:\n",
            "0.4667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4667\n",
            "\tRecall: 0.4667\n",
            "\tF1_Score: 0.4667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#few examples of sentences that are not well classified\n",
        "act_pred = pd.DataFrame()\n",
        "act_pred[\"actual\"] = y_test\n",
        "act_pred[\"predicted\"] = pred_LR\n",
        "act_pred[\"example\"] = df['sentence']\n",
        "\n",
        "incorrect = act_pred[act_pred[\"actual\"] != act_pred[\"predicted\"]]\n",
        "incorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vQKnP3x5B7uP",
        "outputId": "92593729-fdd4-40ae-95c3-7ebfe23b49e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "      <th>example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2255</th>\n",
              "      <td>C1</td>\n",
              "      <td>C2</td>\n",
              "      <td>C'est en décembre 1967, après bien des invecti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>C1</td>\n",
              "      <td>B2</td>\n",
              "      <td>Giscard va pourtant réussir à transformer ce r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2856</th>\n",
              "      <td>A2</td>\n",
              "      <td>B1</td>\n",
              "      <td>Un choix difficile mais important : le public ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1889</th>\n",
              "      <td>B1</td>\n",
              "      <td>C1</td>\n",
              "      <td>Le débat porte plutôt sur l'utilité d'une tell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2358</th>\n",
              "      <td>A2</td>\n",
              "      <td>B1</td>\n",
              "      <td>Il faut du temps et du courage pour soigner to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3959</th>\n",
              "      <td>A1</td>\n",
              "      <td>B1</td>\n",
              "      <td>J'écris un peu.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>A2</td>\n",
              "      <td>B2</td>\n",
              "      <td>Tous les prix sont affichés, mais si besoin, j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>C1</td>\n",
              "      <td>B2</td>\n",
              "      <td>Très présente dans l'alimentation antillaise, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>C1</td>\n",
              "      <td>B1</td>\n",
              "      <td>On réinvente le dimanche dans une perspective ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1940</th>\n",
              "      <td>C1</td>\n",
              "      <td>B2</td>\n",
              "      <td>Pour les femmes surtout, nuancent Régine Lemoi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>512 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     actual predicted                                            example\n",
              "2255     C1        C2  C'est en décembre 1967, après bien des invecti...\n",
              "608      C1        B2  Giscard va pourtant réussir à transformer ce r...\n",
              "2856     A2        B1  Un choix difficile mais important : le public ...\n",
              "1889     B1        C1  Le débat porte plutôt sur l'utilité d'une tell...\n",
              "2358     A2        B1  Il faut du temps et du courage pour soigner to...\n",
              "...     ...       ...                                                ...\n",
              "3959     A1        B1                                    J'écris un peu.\n",
              "4595     A2        B2  Tous les prix sont affichés, mais si besoin, j...\n",
              "891      C1        B2  Très présente dans l'alimentation antillaise, ...\n",
              "1005     C1        B1  On réinvente le dimanche dans une perspective ...\n",
              "1940     C1        B2  Pour les femmes surtout, nuancent Régine Lemoi...\n",
              "\n",
              "[512 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_LR=pipe.predict(df_pred['sentence'])\n",
        "df_sub_LR = pd.DataFrame()\n",
        "df_sub_LR['id']= df_pred['id']\n",
        "df_sub_LR['sentence']= sub_LR\n",
        "df_sub_LR\n",
        "df_sub_LR.to_csv(\"submission_LR_without.csv\")\n",
        "files.download(\"submission_LR_without.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zhm2rVZpL_3N",
        "outputId": "ca77c191-e2ec-4ae6-fbf6-73803f1d2344"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_01bce239-b548-4398-baf4-3915c6aca033\", \"submission_LR_without.csv\", 13393)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxk202I9YnRL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f32c64b-ea70-4161-d88d-48118c603588"
      },
      "source": [
        "# Create a list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "punctuations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAdG9ctDY07D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474e7641-6566-4ccd-812f-c114e35b25a5"
      },
      "source": [
        "stop_words = fr_stop\n",
        "\n",
        "list(stop_words)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['avait',\n",
              " 'directement',\n",
              " 'dix-neuf',\n",
              " 'hormis',\n",
              " 'divers',\n",
              " 'comme',\n",
              " 'siennes',\n",
              " 'permet',\n",
              " 'ni',\n",
              " 'serait']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfJcpLpbZ1gf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "263595c4-a7b5-4d97-a471-074fbe67722d"
      },
      "source": [
        "sp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "# Create tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
        "    ## alternative way\n",
        "    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens\n",
        "\n",
        "# Example\n",
        "sentence = df[\"sentence\"].sample()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Il est également connu pour ses publicités télévisées à faible budget et ses affiches imprimées à Albuquerque, dans lesquels il s\\'annonce principalement sous le slogan : \"Appelez donc Saul !\"'"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlLKEDM0bGNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea613a07-daee-4be3-aba1-6895fe0b6841"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['portable',\n",
              " 'permettre',\n",
              " 'jeune',\n",
              " 'garder',\n",
              " 'espace',\n",
              " 'priver',\n",
              " 'sein',\n",
              " 'vie',\n",
              " 'familial']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxGRlMAue4GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98a8dabe-d197-4ddd-d1df-ed6c25b957b0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Les bioessais effectués ont montré que les mêmes symptômes de morbidité sont observés chez les deux espèces et avec les deux métaux.'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4E8fR7nfOdf"
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGYeND8GWZE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbee0ac5-743f-487b-edfa-04c5640076f2"
      },
      "source": [
        "X = df['sentence'] # the features we want to analyze\n",
        "ylabels = df['difficulty'] # the labels, or answers, we want to test against\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=1234, stratify=ylabels)\n",
        "\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "962     Le réalisateur m'a d'abord demandé de me mettr...\n",
              "1886    Après quelques mois de cette pauvreté noble, a...\n",
              "2721    L'indicateur n'était que de 40% chez les femme...\n",
              "1025    L'objectif de ce type de voyage est d'être act...\n",
              "4048    Et, en France, beaucoup moins de filles que de...\n",
              "                              ...                        \n",
              "3693     Je vais prendre ma douche dans ma salle-de-bain.\n",
              "3408    Après l'éruption de 1754, la plus grosse connu...\n",
              "4289    Léonard est initié par Verrocchio aux nombreus...\n",
              "3312    On en trouve des exemples dans l'ouvrage \"L'in...\n",
              "269     On peut aussi aller au théâtre, dans les musée...\n",
              "Name: sentence, Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlq-PgfRfXrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3e89d7-0b8c-47b2-d109-f61d16f3c35c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "962     B1\n",
              "1886    C1\n",
              "2721    A2\n",
              "1025    B1\n",
              "4048    B2\n",
              "        ..\n",
              "3693    A1\n",
              "3408    B1\n",
              "4289    C2\n",
              "3312    C2\n",
              "269     A1\n",
              "Name: difficulty, Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHDON-DSgn-k"
      },
      "source": [
        "def evaluate(test, pred):\n",
        "    precision = precision_score(test, pred, \n",
        "                                           pos_label='positive',\n",
        "                                           average='micro')\n",
        "    recall = recall_score(test, pred, \n",
        "                                           pos_label='positive',\n",
        "                                           average='micro')\n",
        "    f1 = f1_score(test, pred, average='micro')\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(test, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(test, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZUlu0lF_qQS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaT2bS61faDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a742df-278f-4427-c1fd-98423f8a0fd7"
      },
      "source": [
        "# Use random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "# Define vectorizer\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer) # we use the above defined tokenizer\n",
        "\n",
        "# Define classifier\n",
        "\n",
        "#classifier = RandomForestClassifier(n_estimators=1000, oob_score = 'TRUE')\n",
        "#classifier =svm.SVC(decision_function_shape='ovo')\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)\n",
        "\n",
        "# Evaluation - training set\n",
        "evaluate(y_train, pipe.predict(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[74 32 26 17  8  6]\n",
            " [28 58 35 16 14  8]\n",
            " [15 29 50 31 11 23]\n",
            " [ 5  5 14 64 35 35]\n",
            " [ 2  7  6 33 80 32]\n",
            " [ 3  6 15 24 33 80]]\n",
            "ACCURACY SCORE:\n",
            "0.4229\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4229\n",
            "\tRecall: 0.4229\n",
            "\tF1_Score: 0.4229\n",
            "CONFUSION MATRIX:\n",
            "[[616  22   9   2   0   1]\n",
            " [ 16 612   6   0   2   0]\n",
            " [  9   8 618   1   0   0]\n",
            " [  0   0   2 628   1   3]\n",
            " [  0   0   0   0 638   0]\n",
            " [  0   0   0   0   2 644]]\n",
            "ACCURACY SCORE:\n",
            "0.9781\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.9781\n",
            "\tRecall: 0.9781\n",
            "\tF1_Score: 0.9781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    }
  ]
}